<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Evolving Agents with NEAT</title>
  <link rel="stylesheet" href="../../style.css">
  <link rel="stylesheet" href="../blog-style.css">
  <!-- Font Awesome for icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
  <!-- MathJax for LaTeX rendering -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>
<body>
  <a href="../index.html" class="back-home-btn">Back to Posts</a>
  <div class="blog-container">
    <section class="acknowledgment">
      <h2>Acknowledgment</h2>
      <p>I would like to thank my professor, UTMIST, and the contributors to this project:</p>
      <p><a href="https://www.cs.toronto.edu/~guerzhoy/">Prof. Micheal Guerzhoy</a> created the pong game environment;</p>
      <p><a href="https://jetchiang.co/">Jet Chiang</a> worked on the pong project with me and also used Deep Q Learning to train the pong bot;</p>
      <p><a href="https://www.linkedin.com/in/epic-eric/?originalSubdomain=ca">Eric Xie</a> who helped me with the smash bros project;</p>
      <p><a href="https://www.linkedin.com/in/paul-dong-986531258/?originalSubdomain=ca">Paul Dong</a> who helped me with the smash bros project; and</p>
      <p><a href="https://utmist.gitlab.io/">UTMIST</a> for organizing the smash bros platform.</p>
    </section>

    <header>
      <h1>Evolving Agents with NEAT</h1>
      <p class="intro">
        A deep dive into NeuroEvolution of Augmenting Topologies (NEAT) and its role in evolving intelligent game agents.
      </p>
      <div class="social-icon">
        <a href="https://github.com/HaysonC/NEAT-PongBot" target="_blank" class="icon" title="Pong Bot">
          <i class="fab fa-github"></i>
        </a>
        <a href="https://github.com/HaysonC/NEAT-PongBot" target="_blank" class="icon" title="Smash Bros">
          <i class="fab fa-github"></i>
        </a>
      </div>
    </header>

    <section class="blog-post-content">
      <p>
        <a href="https://en.wikipedia.org/wiki/Neuroevolution_of_augmenting_topologies"><strong>NeuroEvolution of Augmenting Topologies (NEAT)</strong></a> is a groundbreaking method for evolving neural networks using genetic algorithms. Unlike traditional methods that rely on fixed architectures, NEAT starts with minimal networks and progressively complexifies them through evolutionary processes.
      </p>
      <p>
        One of the key ideas behind NEAT is to <a href="https://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf" target="_blank">preserve innovation</a> by protecting new structures through speciation. This allows for a more diverse set of network configurations to be explored.
      </p>
      <p>
        The probability maximizing objective used in many of these evolutionary methods can be expressed as:
      </p>
      <div style="text-align: center; margin: 20px 0;">
        $$\max_\theta \mathbb{E}_{x \sim P}\left[ \log p_\theta(x) \right]$$
      </div>
      <p>
        and we would maximize the expected likelihood of a favorable policy through gradient. However, in NEAT, the objective is to maximize the expected likelihood of a favorable policy through genetic algorithms.
      </p>
      <p>
        In my experiments, I applied NEAT to create a Pong bot and evolve agents for Smash Bros-style games. These projects demonstrate NEAT's potential to generate adaptive, robust solutions even in dynamic and competitive environments.
      </p>
      <p>
        Despite its "retro" reputation compared to modern deep learning techniques, NEAT's evolutionary approach provides unique insights into neural network design. For researchers and practitioners alike, it remains a powerful tool for exploring innovative architectures.
      </p>

      <h2>The Pong Experiment</h2>
      <p><i>Project done in Collaboration with Jet Chiang, <a href="https://jetchiang.co/post/pong/">check it out</a></i></p>
      <p><i>Project done using the neat-python library, <a href="https://neat-python.readthedocs.io/en/latest/">check it out</a></i></p>
      <p>
        When school started, sun shines warmly. I had some spare time to work on a project that I have been wanting to do for a long time.
        I saw videos about evolved creatures and different kinds of games or environments that were evolved. I felt it was very interesting compared
        to deep learning (which are just matrix multiplication in very smart ways). I wanted to simulate the evolution of creatures like how animals evolved.
      </p>
      <p>
        I started with a simple game called <a href="https://en.wikipedia.org/wiki/Pong">Pong</a>. I wanted to see if I could evolve a Pong bot that could play the game well. I used NEAT to evolve the
        neural network that controlled the Pong bot. I was surprised by how well the bot played after a few generations. It was able to beat the game
        against me (that is partly due to my subpar Pong skills). However, just the raw neat is <i>not</i> enough to make the bot play well. Evidently, those who are more <i>gifted</i> in the game of Pong can still beat the bot easily.
      </p>

      <div class="video-container">
        <video controls>
          <source src="pong_demo.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
        <p class="video-description">Demo of a self-play Pong agent trained after 5 minutes.</p>
      </div>

      <h2>How NEAT Works - Speciation, Crossover, and Mutation</h2>
      <p>
        In NEAT, each generation is composed of a population of "genome" structures, which represent neural networks.
        We call those network "phenotypes" of the genome. The network, is simply a directed graph,
        with no concept of "layers" (which we expect in a typical neural network).
        The genome is composed of nodes and connections, where nodes represent neurons and connections represent synapses. The nodes are divided into three types: input, output, and hidden nodes. The connections are weighted and can be either enabled or disabled. The genome is then evaluated based on a fitness function, which determines its performance in the given task.
        As in real evolution, the fittest genomes are selected to reproduce, passing on their genes to the next generation. This process involves crossover and mutation, which introduce new genetic material and drive diversity in the population.
      </p>
      <p>
        One of the important pillars of NEAT is Speciation. Speciation is the process of dividing the population into species based on the similarity of the genomes.
        This is important because it allows the population to maintain diversity and prevents the population from converging to a local optimum. It also protects new innovations from being wiped out as the genome evolves.
        We determine the similarity of two genomes by calculating the compatibility distance between them. The compatibility distance is a measure of how similar two genomes are based on their structure, which is given by the formula:
      </p>
      <div style="text-align: center; margin: 20px 0;">
        $$\delta = c_1 \cdot E + c_2 \cdot D + c_3 \cdot W$$
      </div>
      <p>
        where $$E$$ is the number of excess genes, $$D$$ is the number of disjoint genes, and $$W$$ is the average weight difference of matching genes. The coefficients $$c_1$$, $$c_2$$, and $$c_3$$ are constants that determine the importance of each term.
      </p>
      <p>
        Crossover is the process of combining the genetic material of two parents to produce offspring. In NEAT, crossover is performed by aligning the genes of the parents based on their innovation numbers. Matching genes are inherited randomly from either parent, while disjoint or excess genes are inherited from the more fit parent.
      </p>
      <p>
        Mutation introduces genetic diversity by altering the structure of the genome. In NEAT, mutation can occur in three ways: adding a new node, adding a new connection, or modifying the weight of an existing connection. These mutations allow the genome to explore new network topologies and improve its performance.
      </p>

      <h2>Smash Bros. Evolution</h2>
      <p><i>Project done in Collaboration with Eric Xie, Paul Dong, and Jet Chiang</i></p>
      <p><i>Project done on UTMIST AI^2 Platform, <a href="https://www.utmist.ca/ai2">check it out</a></i></p>
      <p>
        The second time we use neat, is an integration of neat and LSTM on a smash bros game. We used the UTMIST AI^2 platform to create a smash bros game where the agents are evolved using neat. The agents are trained using the neat-python library. The agents are trained to play the game by maximizing the expected likelihood of a favorable policy through genetic algorithms.
      </p>

      <h3>Why did I use rNEAT?</h3>
      <p>
        I used rNEAT because it is a powerful tool for evolving neural networks. It allows for the evolution of complex structures through speciation, crossover, and mutation. rNEAT is particularly well-suited for evolving agents in dynamic and competitive environments, such as games. By combining rNEAT with LSTM, we can create agents that adapt to changing conditions and learn complex strategies over time.
      </p>
      <p>
        For more information on LSTM, check out my post on <a href="../LSTM">LSTM</a>.
      </p>

      <h3>Improvements</h3>
      <p>
        We observe that the agent started to evolve "sensible" moves like trying to attack after a short time. However, neat is extremely dependent on the set up of the training (the reward function, the environment, etc.). The agents seemed to be stuck in a certain local optimum where they just spam the same move over and over again. This is a common problem in neat, where the agents are stuck in a local optimum. This is a problem that is still being researched and is a problem that is still being worked on.
      </p>
      <p>
        I spoke with one of the people that worked in <a href="https://www.youtube.com/@aiwarehouse">AI Warehouse</a>: <a href="https://tanayjyot.vercel.app">Tanayjyot</a>. The suggestion is to also evolve with the hyperparameters of the neat algorithm, by trying different training with different hyperparameters. This is a good suggestion and is something that I will try in the future.
      </p>
    </section>

    <section class="suggested-reading">
      <h2>Suggested Reading</h2>
      <ul>
        <li>
          <strong><a href="https://arxiv.org/pdf/1410.7326" target="_blank">Neuroevolution in Games: State of the Art and Open Challenges</a></strong><br>
          Authors: Sebastian Risi and Julian Togelius<br>
          This paper surveys the application of neuroevolution techniques in gaming, analyzing various neural network types, evolutionary methods, and fitness evaluations.
        </li>
        <li>
          <strong><a href="https://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf" target="_blank">Evolving Neural Networks through Augmenting Topologies</a></strong><br>
          Authors: Kenneth O. Stanley and Risto Miikkulainen<br>
          This foundational paper introduces NEAT, explaining how evolving both neural network topologies and weights can outperform fixed-topology methods.
        </li>
        <li>
          <strong><a href="https://www.cs.utexas.edu/~mhauskn/projects/atari/movies.html" target="_blank">A Neuroevolution Approach to General Atari Game Playing</a></strong><br>
          Authors: Matthew Hausknecht et al.<br>
          This project showcases the application of neuroevolutionary algorithms, including NEAT, to classic Atari 2600 games. The link includes videos demonstrating evolved agents.
        </li>
      </ul>
    </section>
  </div>

  <script src="../blog-script.js"></script>
</body>
</html>
